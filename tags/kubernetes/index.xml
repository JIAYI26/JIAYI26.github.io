<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Kubernetes on JIAYI&#39;s Blog</title>
    <link>https://jiayi26.github.io/tags/kubernetes/</link>
    <description>Recent content in Kubernetes on JIAYI&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Tue, 16 Aug 2022 22:23:48 +0800</lastBuildDate><atom:link href="https://jiayi26.github.io/tags/kubernetes/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Kubernetes概念</title>
      <link>https://jiayi26.github.io/posts/kubernetes%E6%A6%82%E5%BF%B5/</link>
      <pubDate>Tue, 16 Aug 2022 22:23:48 +0800</pubDate>
      
      <guid>https://jiayi26.github.io/posts/kubernetes%E6%A6%82%E5%BF%B5/</guid>
      <description>Kubernetes是什么？ Kubernetes 是一个生产级别的容器编排平台和集群管理系统。用于管理容器化的工作负载和服务，可促进声明式配置和自动化。 Kubernetes 拥有一个庞大且快速增长的生态，其服务、支持和工具的使用范围相当广泛。
传统部署时代 早期，各个组织是在物理服务器上运行应用程序。 由于无法限制在物理服务器中运行的应用程序资源使用，因此会导致资源分配问题。 例如，如果在同一台物理服务器上运行多个应用程序， 则可能会出现一个应用程序占用大部分资源的情况，而导致其他应用程序的性能下降。 一种解决方案是将每个应用程序都运行在不同的物理服务器上， 但是当某个应用程式资源利用率不高时，剩余资源无法被分配给其他应用程式， 而且维护许多物理服务器的成本很高。
虚拟化部署时代 因此，虚拟化技术被引入了。虚拟化技术允许你在单个物理服务器的 CPU 上运行多台虚拟机（VM）。 虚拟化能使应用程序在不同 VM 之间被彼此隔离，且能提供一定程度的安全性， 因为一个应用程序的信息不能被另一应用程序随意访问。
虚拟化技术能够更好地利用物理服务器的资源，并且因为可轻松地添加或更新应用程序， 而因此可以具有更高的可扩缩性，以及降低硬件成本等等的好处。 通过虚拟化，你可以将一组物理资源呈现为可丢弃的虚拟机集群。
每个 VM 是一台完整的计算机，在虚拟化硬件之上运行所有组件，包括其自己的操作系统。
容器部署时代 容器类似于 VM，但是更宽松的隔离特性，使容器之间可以共享操作系统（OS）。 因此，容器比起 VM 被认为是更轻量级的。且与 VM 类似，每个容器都具有自己的文件系统、CPU、内存、进程空间等。 由于它们与基础架构分离，因此可以跨云和 OS 发行版本进行移植。
容器因具有许多优势而变得流行起来，例如：
 敏捷应用程序的创建和部署：与使用 VM 镜像相比，提高了容器镜像创建的简便性和效率。 持续开发、集成和部署：通过快速简单的回滚（由于镜像不可变性）， 提供可靠且频繁的容器镜像构建和部署。 关注开发与运维的分离：在构建、发布时创建应用程序容器镜像，而不是在部署时， 从而将应用程序与基础架构分离。 可观察性：不仅可以显示 OS 级别的信息和指标，还可以显示应用程序的运行状况和其他指标信号。 跨开发、测试和生产的环境一致性：在笔记本计算机上也可以和在云中运行一样的应用程序。 跨云和操作系统发行版本的可移植性：可在 Ubuntu、RHEL、CoreOS、本地、 Google Kubernetes Engine 和其他任何地方运行。 以应用程序为中心的管理：提高抽象级别，从在虚拟硬件上运行 OS 到使用逻辑资源在 OS 上运行应用程序。 松散耦合、分布式、弹性、解放的微服务：应用程序被分解成较小的独立部分， 并且可以动态部署和管理 - 而不是在一台大型单机上整体运行。 资源隔离：可预测的应用程序性能。 资源利用：高效率和高密度。  Kubernetes能做什么？ 容器是打包和运行应用程序的好方式。在生产环境中， 你需要管理运行着应用程序的容器，并确保服务不会下线。 例如，如果一个容器发生故障，则你需要启动另一个容器。 如果此行为交由给系统处理，是不是会更容易一些？</description>
    </item>
    
    <item>
      <title>Kubernetes环境搭建</title>
      <link>https://jiayi26.github.io/posts/kubernetes%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</link>
      <pubDate>Tue, 16 Aug 2022 22:23:09 +0800</pubDate>
      
      <guid>https://jiayi26.github.io/posts/kubernetes%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</guid>
      <description>minikube 下载安装minikube Intel x86_64 curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 sudo install minikube-linux-amd64 /usr/local/bin/minikube Apple arm64 curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-arm64 sudo install minikube /usr/local/bin/ 安装完成之后，你可以执行命令 minikube version，看看它的版本号，验证是否安装成功：
[root@localhost ~]# minikube version minikube version: v1.28.0 安装kubectl minikube kubectl 验证 minikube 环境 前面的工作都做完之后，我们就可以在本机上运行 minikube，创建 Kubernetes 实验环境了。 使用命令 minikube start 会从 Docker Hub 上拉取镜像，以当前最新版本的 Kubernetes 启动集群。不过为了保证实验环境的一致性，我们可以在后面再加上一个参数 &amp;ndash;kubernetes-version，明确指定要使用 Kubernetes 版本。 这里我使用“1.23.3”，启动命令就是（启动 k8s 集群使用root用户时，要加上&amp;ndash;force命令，使用国内镜像，要加上&amp;ndash;image-mirror-country=&amp;lsquo;cn&amp;rsquo;）：
minikube start --kubernetes-version=v1.23.3 --force --image-mirror-country=&amp;#39;cn&amp;#39; 现在 Kubernetes 集群就已经在我们本地运行了，你可以使用 minikube status、minikube node list这两个命令来查看集群的状态：
minikube status minikube node list 有了集群，接下来我们就可以使用 kubectl 来操作一下，初步体会 Kubernetes 这个容器编排系统，最简单的命令当然就是查看版本：</description>
    </item>
    
    <item>
      <title>Kubernetes组件</title>
      <link>https://jiayi26.github.io/posts/kubernetes%E7%BB%84%E4%BB%B6/</link>
      <pubDate>Tue, 16 Aug 2022 22:23:09 +0800</pubDate>
      
      <guid>https://jiayi26.github.io/posts/kubernetes%E7%BB%84%E4%BB%B6/</guid>
      <description>Kubernetes 的基本架构 Kubernetes 采用了现今流行的“控制面 / 数据面”（Control Plane / Data Plane）架构，集群里的计算机被称为“节点”（Node），可以是实机也可以是虚机，少量的节点用作控制面来执行集群的管理维护工作，其他的大部分节点都被划归数据面，用来跑业务应用。
控制面的节点在 Kubernetes 里叫做 Master Node，一般简称为 Master，它是整个集群里最重要的部分，可以说是 Kubernetes 的大脑和心脏。
数据面的节点叫做 Worker Node，一般就简称为 Worker 或者 Node，相当于 Kubernetes 的手和脚，在 Master 的指挥下干活。
Node 的数量非常多，构成了一个资源池，Kubernetes 就在这个池里分配资源，调度应用。因为资源被“池化”了，所以管理也就变得比较简单，可以在集群中任意添加或者删除节点。 Master组件 Master组件为集群做出全局决策，比如资源的调度。 以及检测和响应集群事件，例如当不满足部署的 replicas 字段时， 要启动新的 pod）。
控制平面组件可以在集群中的任何节点上运行。 然而，为了简单起见，设置脚本通常会在同一个计算机上启动所有控制平面组件， 并且不会在此计算机上运行用户容器。
apiserver 是整个 Kubernetes 系统的唯一入口，它对外公开了一系列的 RESTful API，并且加上了验证、授权等功能，所有其他组件都只能和它直接通信，可以说是 Kubernetes 里的联络员。
etcd 是一个高可用的分布式 Key-Value 数据库，用来持久化存储系统里的各种资源对象和状态，相当于 Kubernetes 里的配置管理员。注意它只与 apiserver 有直接联系，也就是说任何其他组件想要读写 etcd 里的数据都必须经过 apiserver。
scheduler 负责容器的编排工作，检查节点的资源状态，把 Pod 调度到最适合的节点上运行，相当于部署人员。因为节点状态和 Pod 信息都存储在 etcd 里，所以 scheduler 必须通过 apiserver 才能获得。</description>
    </item>
    
  </channel>
</rss>
